Graphical representations offer an accessible and actionable means to express and expand our understanding of the world, from observed phenomena to abstract notions, by providing explanations or interpretations based on relationships and connections between elements, circumstances, and complex systems. Graph Neural Networks (GNNs) have emerged as a powerful tool for learning from graph structured data by generalizing the convolution operator to unstructured domains by leveraging message passing or neighborhood aggregation schemes to harness structural information. Recently, in graph machine learning, the classical task of node classification has demonstrated strong results when employing GNNs. 

Despite their potential, GNNs face several known challenges limiting their effectiveness and expressivity; of these obstacles, message passing networks schemes probably can not distinguish specific topologies, such as two triangles from a 6-cycle, and a leading known impediment to GNNs are graphs with high heterophily, namely, graphs whose edges predominantly adjoin nodes of disparate classes, which leads to oversmoothing~\cite{murphy2019relational,sato2021random,li2018deeper}. This paper introduces a graph learning methodology that addresses the limitations of conventional GNNs by offering a novel approach employing hierarchical GNNs-leveraging topological insights from persistent homology, namely persistence filtration, to reveal meaningful structure in graphs informed by class connectivity and allowing for a hierarchy of multilevel graph resolutions. 

The methodologies introduced here learn class relationships between nodes by first initializing edge embeddings from the combined embeddings of the nodes each edge adjoins and assigns edge-level labels as heterophilous or homophilous, learns edge embeddings, and then identifies the likelihood each edge is heterophilous or homophilous. We then leverage the probability assigned to each edge as separating node classes with persistent homology through a persistence filtration function defined over edge values to obtain a multilevel resolution sequence of graphs well suited for hierarchical GNNs. By formulating the learning problem over graph edges, integrating topological summaries, and learning multilevel subgraph hierarchies based on persistent filtration dependent on class connectivity, our approach offers an ordered sequence of graphs that captures both local and global structural information while also addressing critical issues such as over smoothing, reducing computational complexity, and a paradigm for GNNs more resilient to heterophily. We argue that by providing a more nuanced understanding of graph topology and leveraging hierarchical learning, our proposed approach can lead to more resilient, computationally efficient, and expressive GNNs. Empirically, we show that our approach to persistence filtration learning and hierarchical graph learning compares favorably to previous learning techniques, including standard learning models, standard GNNs, and heterophily-specific models. We also demonstrate competitive performance results in accuracy and complexity over established benchmark datasets for evaluating GNN performance in low and high heterophily scenarios.


Our contributions are as follows:
 \begin{itemize}
    \item We propose a homophily-based topological filtration method for graphs, where heterophilous edges may be used for learning but given different emphasis compared to homophilous edges.  Our filtration preserves topological structure compared to approaches that simply drop heterophilous edges. 
    \item We introduce two different methods for improving backbone GNN models, especially on graphs with heterophily, by allowing them to learn from a multi-scale sequence of graphs based on class connectivity and topological filtration.
    \item We experimentally demonstrate that our methods lead to improved node classification accuracy relative to previous models and have the potential to filter out edges added in adversarial attacks. 
    \item A relaxed constraint on GNs to learn a graph representation that a standard GNN can perform best on.
\end{itemize} 