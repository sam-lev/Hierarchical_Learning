This work introduces a second, learnable node filter function for learning the filtration of nodes in graphs within the graph hierarchy during training. The purpose of a learnable node filter function in this context is to, given aÂ multi-scale sequence of graphs for learning, obtain a filtration of graphs of a multiscale sequence of graphs in the graph hierarchy. Filtration of nodes in the graph hierarchy aims to learn which graphs (and their respective nodes) in the nested graph sequence obtained from topological filtration are most informative for multi-scale or hierarchical graph learning. Graph Isomorphism Networks (GIN-$\epsilon$) have been shown to not only be a more expressive learning model, capable of distinguishing different graph structures but also a viable candidate as a learnable filter function for persistent homology when also combined with a multilayer perceptron~\cite{hofer2020graph,xu2018powerful}. We then use a learnable node filter function during Multi-Scale Joint Training defined as 

\[ f_{\epsilon} : \mathbb{R} \times G \times \mathbb{V} \to \mathbb{R}\text{ , }(\epsilon, \nodeSet_p, u) \mapsto f( \epsilon, \nodeSet_p, u)\]
where
\[f_p( \nodeSet_p, u):= \text{MLP}(\text{GIN}^p_{\epsilon}(h^p_u))\to\mathbb{R}\]. 

where $h^p_u$ is the embedding representation of node $u$ in $\nodeSet_p$ in graph $G_p=(\nodeSet_p, \edgeSet_p)$ for graph level $p$ of the graph hierarchy and  $f_\epsilon$ a for differentiable node filter function using a $\text{GIN}^p_{\epsilon}$ which is learnable and differentiable in $\epsilon$ and MLP is a multilayer perceptron which takes the resulting embedding from $GIN_{\epsilon}^p$ and produces a single dimensional output. The resulting real output of $f_p$ is the learned filter value denoted $q_p$ for node $u$ in graph level $G_p$.

This work introduces a methodology for using the learned filter value $q_p$ to filter graphs within the graph hierarchy. To learn the importance and reduce or increase the contribution of graphs in the graph hierarchy during multi-scale joint aggregation we use the $q_p$ filter value for attention type based aggregation by weighing the aggregated embedding obtained from graph $G_p$ in the hierarchy before multi-scale aggregation across all graphs $G_i$ in the multi-scale filtration sequence of $P$ graphs $G_0,G_1,\cdots ,G_P$.   Before the combination step of multi-scale aggregation, we then factor each node's resulting embedding from each graph level by its respective filter value $q_p$ In doing so, the learned filter value can learn to eliminate or accentuate the contribution of embeddings from specific graphs in the multi-scale graph sequence.

The learned filtration of graphs in the graph hierarchy during multi-scale joint aggregation can then be expressed as the combined embedding from each subgraph, where each subgraph's embedding is obtained with a back bone GNN and a filter function $f_p(\nodeSet_p,u)$, unique to each graph level, for a final embedding that is weighted by a filter value $q_p$ before global combination. For node $v_P$ in the highest resolution graph $G_P$ in the filtration sequence we then have:

\begin{align*}
h_{v_P}^{k} = COMBINE\big( q_0\cdot f_i(h_{v_0}^{k-1}), q_1 \cdot f_1(h_{v_1}^{k-1}),\cdots,q_{P} \cdot f_P(h_{v_P}^{k-1})\big)
\end{align*}
 
Once a learned filter value is assigned to nodes, performing another level of topological filtration over the initial multiscale graph sequence is also possible. With filter values assigned to nodes, one can easily perform a topological filtration of each subgraph in the graph hierarchy, effectively gaining a more informed multi-scale graph filtration sequence suitable for learning and preserving topological information contained in each graph and consisting of more informative hierarchical graph representations. 